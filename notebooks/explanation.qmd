---
title: "Funda code explanation"
format:
    html:
        code-fold: false
        table-of-contents: true
        toc-location: left
---

## Introduction

This explanation guides you through the Funda example. It highlights the most important aspects and explains several design choices. Note that only the code in modules is discussed. The explorations in the Jupyter notebook speak for themselves.

## Project structure

First, we take a look at the structure of the project folder:

```
├── .git                            <- Local Git repository for this project.
├── README.md                       <- A Markdown file with a project overview.
├── data                            <- Directory containing the project data.
│   └── price_list.csv
├── .gitignore                      <- Lists files to be excluded from version control.
├── notebooks                       <- Slightly less common but a good place for all 
│   ├── explanation.qmd                exploratory documents.
│   ├── funda.ipynb
│   ├── pricelist_maarssen.csv
│   ├── tmp.html
│   └── ...
├── poetry.lock                     <- Lists of ALL dependencies of the project.
├── pyproject.toml                  <- Project settings, including DIRECT dependencies.
├── src                             <- Directory with the source code
│   ├── __init__.py                    (Poetry will give it the project name by default.)
│   ├── main.py
│   ├── prices.py
│   ├── settings.py
│   └── ...
└── tests                           <- Directory with all test code that can be run
    └── __init__.py                    with a test framework (e.g. Pytest).
```

This is a very common way to structure your project. If you use [Poetry](https://python-poetry.org/), to create the project, it will provide you with most of this structure 
by default.

A few additional notes on some of the files and directories:

- `.git`: The `.git` directory is created if you run `git init .` in the project directory and bring it under version control. It contains the project's local Git repository. Its content is encoded and hashed and not meant for manual inspection or modification. 

- `.gitignore`: The `.gitignore` specifies which files should not be tracked by Git. These could be, for example, cache files or security keys, which should not be excluded from the repository. 

- `README.md`: It is good practice to include a `README.md` file (a [markdown file](https://www.markdownguide.org/)) in the home directory of your project. If you add your project repository to [GitHub](https://github.com/), a HTML-version of this file is shown as the project's home page.

- `poetry.lock`/`pyproject.toml`: If you add packages to your project (e.g. [`requests`](https://pypi.org/project/requests/)), your project becomes dependent on that package and maybe even on the specific version of it. These dependencies themselves may as well depend on other packages (and even specific versions). Poetry manages these dependencies and helps you to create reproducible code with predictable results regardless the machine it is run on. In `pyproject.toml`, you specificy (either using Poetry or manually) the *direct* dependencies of your project, while the lock file contains *all* dependencies of the project (i.e. including the dependencies your direct dependencies depend on). You can regard `poetry.lock` as a cache file. You can remove it safely and Poetry will recreate it the next time you run `poetry update`.

- `src`: `src` contains the source code (`.py` files) of your project. It is good practice to turn it into a [Python package](https://docs.python.org/3/glossary.html#term-package) by including an empty `__init__.py` file.

- `tests`: `tests` contains the test code (`.py` files) of your project. This code can be used to systematically run unit tests and other tests on your code. Wellknown frameworks for testing in Python are [`unittest`](https://docs.python.org/3/library/unittest.html?highlight=unittest#module-unittest) from the Python standard library and [`pytest`](https://docs.pytest.org/). The `tests` directory is also often turned into a package by adding an empty `__init__.py` to it. 

## Source code files in `src`

Organizing the logic of your code in separate files in the `src` directory can be a topic of a lot of debate. Most developers, however, have the same aim and that is to organize their code in simple building blocks that can be assembled into larger and more complex units. Therefore, it is good practice to separate the logic of your code in simple and clear units. Each unit should contain a single piece of work with a clear name and it should be more or less independent of other units. 

Organizing your code in a clear structure makes it better because a separate piece of work with a single and clearly defined task ([single responsibility principle](https://en.wikipedia.org/wiki/Single-responsibility_principle)) is better testable, readable, maintainable and extensible.

Some of the design decisions:

- `settings.py` Store all parameters of your project (i.e. hard-coded things like file locations or URLs) in a single place. Although it adds some overhead, it makes it easy to adjust the project configuration parameters without having to make changes at many different places. 

- `main.py` This is the main entrance to the code. You can run the project with `python src/main.py`. Note that the parameters of the project (e.g. the destination file) are controlled by `settings.py`. Alternatively, this could also be controlled by a graphical user interface or by a command line interface. It is relatively simple to add a command line interface to your module. This is discussed [below](#adding-a-command-line-interface-to-main.py).

- `prices.py` This is the module that contains the actual logic. Yet it has a clear and well-defined task: to retrieve the prices from the specified URL and save it to the specified file. Other such modules with different tasks might be added to the project later. `main.py` would than contain some more logic to control the interaction with the additional modules.

The modules are discussed in more detail below.

## `settings.py`

The `settings.py` file starts with a short description in a docstring (`"""Settings module..."""`). This is the [recommended way](https://peps.python.org/pep-0257/) to provide documentation in Python. 

For settings management, a subclass of the `BaseSettings` from [`pydantic`](https://docs.pydantic.dev/) is used. In this case, this may be a bit overkill, since a simple `dataclass` would have done as well. Pydantic offers a lot of validations, which may especially be usefull in larger project and projects with configurations that can be managed by end-users.

If a data class was used instead of `pydantic.BaseSettings`, the code would have looked like:

```python
from dataclasses import dataclass

@dataclass
class _Settings:
    ...

settings = _Settings()

```

Classes will be studied in more detail later in the course, but a few things should be noted here.

The name of the class starts with `_`, which, in Python idiom, indicates that it is meant for internal use (within the module) only. In Java, the class would have been private.

With `settings = _Settings()`, the class is instantiated (i.e. an object of the class is created) directly after its definition. This is a quick-and-dirty way to mimic the so-called [Singleton design pattern](https://refactoring.guru/design-patterns/singleton), which aims to have only a single object (instance) of a class in a project. This ensures that 'dynamic' settings (e.g. creating a temporary file in the `_Settings` class) can be shared between the modules of the project. 

Other modules should import the `settings` object directly and not create instances of the `_Settings` class themselves:

```python
# Correct: 

# some_other_module.py                 
from settings import settings             # Import the settings object.

some_setting = settings.some_setting      # Use a setting.

# Wrong:

# some_other_module.py
from settings import _Settings
presets = _Settings()                     # Create a new settings object.

some_setting = presets.some_setting       # Use a setting.
```
Logging is not implemented in this project, but if it would, the logger objects and settings would also be stored in the `settings.py`. These are also most often implemented according to the singleton pattern.

The settings themselves are attributes of the `_Settings` class. Within the class, a  defined attribute can be used right after its initialization (e.g. `base_dir` is used in the line following its definition). 

The names of all attributes of the `_Settings` class are followed by a colon and a data type (e.g. `base_dir: Path`). The so-called [*type hints*](https://realpython.com/python-type-checking/) form a safety mechanism that helps to detect errors with static code checkers (linters). Type hints were introduced in Python 3.5 and they are used more and more. They are optional, but they may help to detect possible bugs in an early stage of development.

Note how the project root directory is stored in `base_dir`:

```python
base_dir: Path = Path(__file__).parents[1]
```
This might seem a bit cumbersome (we could have written `base_dir: Path = Path.cwd()` as well) but it is more robust, especially when the module is imported in a Jupyter notebook.

`__file__` is a special variable that is available in each Python module. It contains the full filename of the module (including its path) as a string. With `Path(__file__)`, a `Path` object is created from the string. `parents` is one of its attributes and it contains the ancestors of a path:

```python
p = Path('/home/code/funda/src/settings.py')
p.parents[0]  # '/home/code/funda/src'
p.parents[1]  # '/home/code/funda'
p.parents[2]  # '/home/code'
```

Note that because all settings are stored in a single place it would not be very difficult to rewrite the module and work, for example, with a JSON file for the project configuration. Only `settings.py` would have to be modified, while all other modules could remain unchanged.

## `prices.py`

The file `prices.py` contains all the 'business logic' of the project. It starts with a docstring, the import of the required modules and the definition of some global variables. Most of the file consists of function definitions.

### Module imports

Note that most `import` statements import entire modules (e.g. `import csv`). This is recommended to avoid conflicts in variable names. `Path` and `settings` are exceptions, because they are very often used and it would be tedious and less readable to write `pathlib.Path` or `settings.settings` each time. 

### Global variables

Some options are stored in global variables (e.g. `HEADERS`). This makes it clear in the code that their values are governed on a global (project or module) level.

### Functions

The file contains quite a few functions. In some cases, it might seem overkill to use a function, but there still may be good reasons to do so. In any case, deciding which code to put in a function and how to name them is an art. There are no strict rules and different developers will make different (design) choices.

Although functions are primarily meant to prevent copying the same (or slightly modified) code over and over again, they also help to separate very specific logic (which may need to be modified more often) from more general logic and to isolate complexities that need to be tested more thoroughly. In addition, moving complexities to a function and label them with a clear (function) name makes code more readable.

The order of the function definitions is actually not important for Python but to increase readability it is good practice to try to organize them in a logical order.

All functions have type annotions on their arguments (e.g. `base_url: str`). If the function is used in another module (e.g. `from prices import export_prices`), VS Code will detect it if another data type is fed into the function. Also the return type of the function is specified using the arrow notation (`-> list[str]`). The use of type hints is optional. You don't have to use them and in some cases it may complicate matters more than it helps.

### Remarks on the functions

#### `export_prices()`

- The 'main' function of the module that controls the main flow of the module is a short function, but it calls three other functions in the module (`construct_page_urls()`, `search()` and `price_row()`) that each, in turn, call other functions. 
- `price_list` is filled using a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html?highlight=list%20comprehension#list-comprehensions).
- The CSV file is opened with a context manager (`with open(...)`), which is the recommended way of opening a file. If an error occurs, the context manager will automatically close the file properly. 
- The options for the CSV file (e.g. which delimiter should be used) are controlled by `CSV_OPTIONS`, which is a dictionary. The `**` operator unpacks the dictionary and turns it into a list of named arguments. This is called [*argument unpacking*](https://docs.python.org/3/tutorial/controlflow.html#tut-unpacking-arguments). Hence, the options defined in `settings.csv_options` (in `settings.py`) are directly passed to the CSV writer. 

#### `get_html()`

- Makes a web request and receives its response. 
- The error handling is rather basic. In case of network or web requests, things might easily go wrong, so in a real-world situation, this might need more attention (e.g. using `try ... except ...` and retries).
- The status code of the response (a code defined in the [HTTP protocol](https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)) is defined in the `HTTPStatus` enumeration in the `http` module of the standard library. We could as well have written `if resp.status_code == 200` but for reasons of readability it is generally preferrable to avoid hard-coded 'magic' numbers. The name `HTTPStatus.OK` makes it very clear what we are checking even for those who are not familiar with the HTTP protocol and status code 200.

#### `construct_page_urls()`

- This function contains some specific logic that typically may have to be modified sooner than other code in the project. If Funda decides to redesign their website and use a different pagination system, this function would have to rewritten. 
- To find the maximum number of pages, a generator expression (comparable to a list comprehension) is used as an argument to the `max()` function.

#### `search()`

- This function also contains some specific logic that depends on how the Funda website organizes the search results (using `<li class="search_result">... </li>`).

#### `price_row()`

This function calls the more business-specific parse functions and communicates very clearly what a price row comprises.

#### `parse_address()` and `parse_price()`

These functions both call their `clean_` counterpart and you might debate whether these shouldn't be incorporated in the `parse_` functions themselves. However, because cleaning may involve quite some steps (as in `clean_price`) that may be subject to change and because code is generally easier to understand when the same steps are followed for the same things (so a parse and a clean step for both address and price), we separate them.

#### `clean_address()` and `clean_price()`

- `clean_address()` is very simple and it seems overkill to define a function for it. However, the Funda website might change in the future, making it necessary to add more cleaning steps. 
- `clean_price()` applies so-called method chaining, which means that the same method as called repeatedly in a single statement. 

## `main.py`

The `main.py` file is the entry point for the project code. It can be run either directly from the command line using:
```bash
python src/main.py
```
Or, it could be imported into another project. Then it would read (depending on the exact package name etc.) something like:

```python
import funda

funda.main(...)
```
Despite its name, `funda.main` would not be the main entry point of that project in the latter case. 

To be able adjust the behavior of a module to these two use cases, Python provides the following (very common) construction:

```python
# mymodule.py

def myfunc():   # The function definition.
    ...

if __name__ == '__main__':
    myfunc()    # The function call.
```

If `mymodule.py` is run on its own from the command line using `python mymodule.py`, the variable `__name__` will have the value `"__main__"` and the function `myfunc` will be both defined and called.

If  `mymodule.py` is imported into another module `import mymodule`, the variable `__name__` will have another value and then the function `myfunc` will be defined but not called.

## Adding a command line interface to `main.py`

As pointed out [above](#source-code-files-in-src), we have chosen to control the parameters of the project (e.g. the path and name of the destination file) by the `settings.py` module. We could as well have chosen to add a command line interface to it. Then, we would for example be able to specify the destination file on the command line. For example:

```bash
python src/main.py --dest_file=data/other_file.csv
```

There are several options for adding a command line interface to your project. You can use third-party packages (e.g. [click](https://click.palletsprojects.com/)) or you can use the package [`argparse`](https://docs.python.org/3/library/argparse.html?highlight=argparse#module-argparse) from the standard library.

If we use `argparse`, our `main.py` would look like:

```python
import argparse
from pathlib import Path

# Other imports and body remain the same.
... 

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--dest_file',
        type=Path, 
        help='The destination file (CSV) of exported prices.',
        required=True
    )
    args = parser.parse_args()

    base_url = settings.url
    csv_file = args.dest_file  # Use command line argument instead of setting.
    main(base_url, csv_file)
```
Note that the parser is added to the conditional part of the module (below `if __name___ == ...`), which makes sense because we only use this interface if the module is run as the main module. 

You can recognize three steps:

1. Create an `ArgumentParser` object. This does the magic.

1. Configure the parser object (i.e. make it recognize one argument `--dest_file`).

1. Let the parser do the actual parsing.

After these steps, the object `args` is available with the arguments as attributes.

Note that `argparse` provides some nice functionality out of the box. If you run the file but forget to specify the destination, an error message is shown:

```bash
usage: main.py [-h] --dest_file DEST_FILE
main.py: error: the following arguments are required: --dest_file
```

You can also print a help message from the command line with the `-h` option that is added by default:
```bash
python src/main.py -h
```
shows:

```bash
usage: main.py [-h] --dest_file DEST_FILE

optional arguments:
  -h, --help            show this help message and exit
  --dest_file DEST_FILE
                        The destination file (CSV) of exported prices.
``` 


The `argparse` package provides a lot more functionality that allows you to create advanced command line interfaces. You can read more about it in the [Argparse Tutorial](https://docs.python.org/3/howto/argparse.html?highlight=argparse#argparse-tutorial) on the Python website.

